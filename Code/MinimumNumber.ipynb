{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad667938-6913-47de-b3ed-05d027a456cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.models import AlexNet_Weights\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device object\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b37eea0-3985-4bff-ac4d-272790d8b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   #must same as here\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(), # data augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # normalization\n",
    "])\n",
    "transforms_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   #must same as here\n",
    "     transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6376de0-b332-4a02-bd73-f968d3a17021",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"dataset/caltech256/256_ObjectCategories\" \n",
    "dataset = datasets.ImageFolder(data_dir, transforms_train)\n",
    "\n",
    "data_dir = \"Min_number_stop\" \n",
    "stop = datasets.ImageFolder(data_dir, transforms_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34731917-ba37-4766-8baf-6bfe5a2499aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes Caltech256:  257\n",
      "Number of class stop directory:  1\n",
      "Number of images in dataset:  30614\n"
     ]
    }
   ],
   "source": [
    "class_names = dataset.classes\n",
    "class_num = len(class_names)\n",
    "print(\"Number of classes Caltech256: \", class_num)\n",
    "stop_class = stop.classes\n",
    "class_num = len(stop_class)\n",
    "print(\"Number of class stop directory: \", class_num)\n",
    "print(\"Number of images in dataset: \", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93467679-c0b2-4908-8526-2ad1566c748d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (1st subset) size: 7653\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.25 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train1, _ = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "print('Train (1st subset) size:', len(train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "597a80e4-76e3-4c07-ab59-d6a87ced5bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (2st subset) size: 15307\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.5 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train2, _ = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "print('Train (2st subset) size:', len(train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "842d2e61-3a39-4025-8995-7b3e432058bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (2st subset) size: 22960\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.75 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train3, _ = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "print('Train (2st subset) size:', len(train3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6611246-5aa0-499f-81b5-dd3d08ebc1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (2st subset) size: 27552\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.9 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train4, _ = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "print('Train (2st subset) size:', len(train4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39599fb2-9444-428c-8c7b-f1ef2cc36d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_dataloader =  torch.utils.data.DataLoader(train1, batch_size=12, shuffle=True, num_workers=8)\n",
    "train2_dataloader =  torch.utils.data.DataLoader(train2, batch_size=12, shuffle=True, num_workers=8)\n",
    "train3_dataloader =  torch.utils.data.DataLoader(train3, batch_size=12, shuffle=True, num_workers=8)\n",
    "train4_dataloader =  torch.utils.data.DataLoader(train4, batch_size=12, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9801fe65-3674-4d15-a51e-300a1ed2beec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop train dataset size: 16\n",
      "Stop test dataset size: 48\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.25 * len(stop))\n",
    "test_size = len(stop) - train_size\n",
    "train_stop_1, test_stop_1 = torch.utils.data.random_split(stop, [train_size, test_size])\n",
    "print('Stop train dataset size:', len(train_stop_1))\n",
    "print('Stop test dataset size:', len(test_stop_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e0f673a-cf6c-4007-97bb-cb2084e2060f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop train dataset size: 32\n",
      "Stop test dataset size: 32\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.5 * len(stop))\n",
    "test_size = len(stop) - train_size\n",
    "train_stop_2, test_stop_2 = torch.utils.data.random_split(stop, [train_size, test_size])\n",
    "print('Stop train dataset size:', len(train_stop_2))\n",
    "print('Stop test dataset size:', len(test_stop_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eb564fe-b177-4089-8fbd-910941457387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop train dataset size: 48\n",
      "Stop test dataset size: 16\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.75 * len(stop))\n",
    "test_size = len(stop) - train_size\n",
    "train_stop_3, test_stop_3 = torch.utils.data.random_split(stop, [train_size, test_size])\n",
    "print('Stop train dataset size:', len(train_stop_3))\n",
    "print('Stop test dataset size:', len(test_stop_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d34d221-1c52-4b38-aaaa-6373a1bf4dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop train dataset size: 57\n",
      "Stop test dataset size: 7\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.9 * len(stop))\n",
    "test_size = len(stop) - train_size\n",
    "train_stop_4, test_stop_4 = torch.utils.data.random_split(stop, [train_size, test_size])\n",
    "print('Stop train dataset size:', len(train_stop_4))\n",
    "print('Stop test dataset size:', len(test_stop_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6873c5c3-f72f-4a2c-afd8-8e10293d0909",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_stop =  torch.utils.data.DataLoader(train_stop_1, batch_size=12, shuffle=True, num_workers=8)\n",
    "test1_stop = torch.utils.data.DataLoader(test_stop_1, batch_size=12)\n",
    "train2_stop =  torch.utils.data.DataLoader(train_stop_2, batch_size=12, shuffle=True, num_workers=8)\n",
    "test2_stop = torch.utils.data.DataLoader(test_stop_2, batch_size=12)\n",
    "train3_stop =  torch.utils.data.DataLoader(train_stop_3, batch_size=12, shuffle=True, num_workers=8)\n",
    "test3_stop = torch.utils.data.DataLoader(test_stop_3, batch_size=12)\n",
    "train4_stop =  torch.utils.data.DataLoader(train_stop_4, batch_size=12, shuffle=True, num_workers=8)\n",
    "test4_stop = torch.utils.data.DataLoader(test_stop_4, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "708cf54d-5df4-40b5-8a32-7e00c0efaa8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.alexnet(weights = AlexNet_Weights.IMAGENET1K_V1)  \n",
    "# Freeze all the pre-trained layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "model.classifier = nn.Sequential(*[model.classifier[i] for i in range(5)])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc695f87-c27b-46ae-9dc9-bf2fa5775c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc34b33f-dcc0-4c88-8d73-fd6cf279896e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature vectors for train set (before tag insertion): 7653\n",
      "Number of feature vectors for train set (after tag insertion): 7669\n",
      "Knn average test accuracy: 0.6225\n"
     ]
    }
   ],
   "source": [
    "accuracy_train = []\n",
    "features = []\n",
    "f_labels = []\n",
    "\n",
    "for i, data in enumerate(train1_dataloader):\n",
    "    image, labels = data\n",
    "    image = image.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    batch_features = model(image)\n",
    "\n",
    "    for j in range(image.size()[0]):\n",
    "        features.append(batch_features[j].cpu().numpy())\n",
    "        f_labels.append(labels[j].cpu().numpy()) \n",
    "\n",
    "print(f\"Number of feature vectors for train set (before tag insertion): {len(features)}\")\n",
    "\n",
    "for i, data in enumerate(train1_stop):\n",
    "    image, labels = data\n",
    "    image = image.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    batch_features = model(image)\n",
    "\n",
    "    for j in range(image.size()[0]):\n",
    "        features.append(batch_features[j].cpu().numpy())\n",
    "        f_labels.append(labels[j].cpu().numpy())\n",
    "\n",
    "print(f\"Number of feature vectors for train set (after tag insertion): {len(features)}\")\n",
    "knn.fit(features, f_labels)\n",
    "\n",
    "for i in range(100):\n",
    "    test_features = []\n",
    "    test_labels = []\n",
    "\n",
    "    for i, data in enumerate(test1_stop):\n",
    "        image, labels = data\n",
    "        image = image.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        batch_features = model(image)\n",
    "\n",
    "        for j in range(image.size()[0]):\n",
    "            test_features.append(batch_features[j].cpu().numpy())\n",
    "            test_labels.append(labels[j].cpu().numpy())\n",
    "\n",
    "    pred = knn.predict(test_features)\n",
    "    accuracy = accuracy_score(test_labels, pred)\n",
    "    accuracy_train.append(accuracy)\n",
    "    #print(\"Knn test accuracy:\", accuracy)\n",
    "\n",
    "print(\"Knn average test accuracy:\", np.mean(accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153153f1-4ceb-4911-827a-fa3361915a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
